{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hGgnodWuvilY",
    "outputId": "24a03d0b-1a43-4359-9fa5-4ca1beb6f578"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_tuner in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.4.7)\n",
      "Requirement already satisfied: keras in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras_tuner) (3.7.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras_tuner) (24.2)\n",
      "Requirement already satisfied: requests in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras_tuner) (2.32.3)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras_tuner) (1.0.5)\n",
      "Requirement already satisfied: absl-py in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras->keras_tuner) (2.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras->keras_tuner) (2.0.2)\n",
      "Requirement already satisfied: rich in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras->keras_tuner) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras->keras_tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras->keras_tuner) (3.12.1)\n",
      "Requirement already satisfied: optree in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras->keras_tuner) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from keras->keras_tuner) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->keras_tuner) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->keras_tuner) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->keras_tuner) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->keras_tuner) (2024.8.30)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from optree->keras->keras_tuner) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rich->keras->keras_tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rich->keras->keras_tuner) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\casey\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yX1hCC1HuT_U"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import keras_tuner as kt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13fLmUg0LOSM"
   },
   "source": [
    "---\n",
    "\n",
    "Text Cleaning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VWaQ1ETOKSDk"
   },
   "outputs": [],
   "source": [
    "def dataprep(df):\n",
    "    df['text'] =  df['text'].astype(str)\n",
    "    df['text'] =  df['text'].str.replace(r\"@[\\w]+\", '', regex=True)\n",
    "    df['text'] =  df['text'].str.replace(r\"http[s]?://\\S+\", '', regex=True)\n",
    "    df['text'] = df['text'].str.replace(r\"[/'-]\", ' ', regex=True)\n",
    "    df['text'] =  df['text'].str.replace(r\"&\", ' & ', regex=True)\n",
    "    df['text'] =  df['text'].str.replace(r'[?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~“”’]', '', regex=True)\n",
    "\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNVtWK00DSxG"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "Positional Encoding Function\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KDk4Ml3Au3WI"
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = tf.range(position, dtype=tf.float32)[:, tf.newaxis] / tf.pow(10000.0, (2 * (tf.range(d_model, dtype=tf.float32)[tf.newaxis, :] // 2)) / tf.cast(d_model, tf.float32))\n",
    "    angle_rads_sin = tf.sin(angle_rads[:, 0::2])\n",
    "    angle_rads_cos = tf.cos(angle_rads[:, 1::2])\n",
    "    angle_rads_updated = tf.concat([angle_rads_sin, angle_rads_cos], axis=-1)\n",
    "    pos_encoding = angle_rads_updated[tf.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RBHxKqjjDc-7"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "Obtaining the max length of a tweet - Used for Padding, Input Layer Shape and Positional Encoding\n",
    "\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GvUxJ4KkzkaO"
   },
   "outputs": [],
   "source": [
    "def determine_maxlen(sequences, percentile=99):\n",
    "    seq_lengths = [len(seq) for seq in sequences]\n",
    "    maxlen = int(np.percentile(seq_lengths, percentile))\n",
    "\n",
    "    return maxlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAE4N-EWBpPX"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "**Build Function Breakdown**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "*  Step 1 - Setup Hyperparam options\n",
    "*  Step 2 - Update optimizer based on selection\n",
    "*  Step 3 - Create input Layer\n",
    "*  Step 4 - Converts tokens into dense vectors\n",
    "*  Step 5 - Apply positional encoding\n",
    "*  Step 6 - Add sentence context to words (Self-Attention)\n",
    "*  Step 7 - Dropout to avoid overfitting\n",
    "*  Step 8 - Pool (Equivalent of flatten - Groups all vectors into 1) and Normalize\n",
    "*  Step 9 - Add dense and dropout layers\n",
    "*  Step 10 - Create sigmoid (binary) output layer\n",
    "*  Step 11 - Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EUnILlY_uvNi"
   },
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    max_length = hp.Int('max_length', min_value=20, max_value=50, step=5)\n",
    "    d_model = 128\n",
    "\n",
    "    # Step 1: Tuning hyperparameters\n",
    "    num_heads = hp.Int('num_heads', min_value=2, max_value=8, step=2)\n",
    "    key_dim = hp.Int('key_dim', min_value=40, max_value=56, step=4)\n",
    "    dense_units = hp.Int('dense_units', min_value=64, max_value=512, step=32)\n",
    "    dropout_rate = hp.Float('dropout_rate', min_value=0.2, max_value=0.5, step=0.05)\n",
    "    optimizer_choice = hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop'])\n",
    "    lr = hp.Float('lr', min_value=1e-5, max_value=1e-2, sampling='log')\n",
    "    activation = hp.Choice('activation', values=['relu', 'tanh', 'swish'])\n",
    "\n",
    "    # Step 2: Select optimizer\n",
    "    if optimizer_choice == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr)\n",
    "    elif optimizer_choice == \"rmsprop\":\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else:\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "\n",
    "    # Step 3: Build model\n",
    "    inputs = layers.Input(shape=(max_length,))\n",
    "\n",
    "    # Step 4:Embedding + Positional Encoding\n",
    "    embedding = layers.Embedding(input_dim=len(tokenizer.word_index) + 1,\n",
    "                                 output_dim=d_model,\n",
    "                                 input_length=max_length)(inputs)\n",
    "    positional_encoding_output = positional_encoding(max_length, d_model)\n",
    "    embedding = embedding + positional_encoding_output\n",
    "\n",
    "    # Step 5:Multi-Head Attention\n",
    "    transformer_block = layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim)(embedding, embedding)\n",
    "    transformer_block = layers.Dropout(rate=dropout_rate)(transformer_block)\n",
    "    transformer_block = layers.LayerNormalization()(transformer_block)\n",
    "\n",
    "    # Step 6:Pooling and Dense Layer\n",
    "    x = layers.GlobalAveragePooling1D()(transformer_block)\n",
    "    x = layers.Dense(units=dense_units, activation=activation)(x)\n",
    "    x = layers.Dropout(rate=dropout_rate)(x)\n",
    "\n",
    "    # Step 7:Output Layer\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    # Step 8:Compile Model\n",
    "    model = tf.keras.models.Model(inputs, outputs)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wh-PXeNWD0Vf"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "Load Data\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "921Y10Y7uzkR"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "train_df = dataprep(train_df)\n",
    "train_df = dataprep(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuQdwH3PD22L"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "Sample dataset to see if cleaning worked\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "Bm5IapdAu9LG",
    "outputId": "4bdc6115-4786-46c9-f4e6-c02cfa698307"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>393</td>\n",
       "      <td>annihilation</td>\n",
       "      <td>BIG D  HOUSTON/BOSTON/DENVER</td>\n",
       "      <td>U.S National Park Services Tonto National Fore...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>1335</td>\n",
       "      <td>blown%20up</td>\n",
       "      <td>801 SL,UT</td>\n",
       "      <td>Damn greinke got blown up in that first inning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>254</td>\n",
       "      <td>ambulance</td>\n",
       "      <td>Happily Married with 2 kids</td>\n",
       "      <td>AMBULANCE SPRINTER AUTOMATIC FRONTLINE VEHICLE...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3646</th>\n",
       "      <td>5195</td>\n",
       "      <td>fatalities</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Sharing to help our cousin s family</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>5305</td>\n",
       "      <td>fear</td>\n",
       "      <td>Halifax</td>\n",
       "      <td>The number of people denying climate change on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6694</th>\n",
       "      <td>9591</td>\n",
       "      <td>thunder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My brother is crying cause the thunder lmao</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>2937</td>\n",
       "      <td>danger</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Danger and Excitement of Underwater Cave D...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7505</th>\n",
       "      <td>10735</td>\n",
       "      <td>wreckage</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Wreckage  Conclusively Confirmed  as From MH37...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1832</th>\n",
       "      <td>2633</td>\n",
       "      <td>crashed</td>\n",
       "      <td>Gujranwala, Pakistan</td>\n",
       "      <td>Maj Muzzamil Pilot Offr of MI 17 crashed near ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6477</th>\n",
       "      <td>9264</td>\n",
       "      <td>sunk</td>\n",
       "      <td>London, England</td>\n",
       "      <td>It still hasn t sunk in that I ve actually met...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id       keyword                      location  \\\n",
       "270     393  annihilation  BIG D  HOUSTON/BOSTON/DENVER   \n",
       "922    1335    blown%20up                     801 SL,UT   \n",
       "178     254     ambulance  Happily Married with 2 kids    \n",
       "3646   5195    fatalities                     Wisconsin   \n",
       "3733   5305          fear                       Halifax   \n",
       "6694   9591       thunder                           NaN   \n",
       "2047   2937        danger                           NaN   \n",
       "7505  10735      wreckage                        Mumbai   \n",
       "1832   2633       crashed          Gujranwala, Pakistan   \n",
       "6477   9264          sunk               London, England   \n",
       "\n",
       "                                                   text  target  \n",
       "270   U.S National Park Services Tonto National Fore...       0  \n",
       "922      Damn greinke got blown up in that first inning       0  \n",
       "178   AMBULANCE SPRINTER AUTOMATIC FRONTLINE VEHICLE...       0  \n",
       "3646               Sharing to help our cousin s family        0  \n",
       "3733  The number of people denying climate change on...       0  \n",
       "6694        My brother is crying cause the thunder lmao       0  \n",
       "2047  The Danger and Excitement of Underwater Cave D...       0  \n",
       "7505  Wreckage  Conclusively Confirmed  as From MH37...       1  \n",
       "1832  Maj Muzzamil Pilot Offr of MI 17 crashed near ...       1  \n",
       "6477  It still hasn t sunk in that I ve actually met...       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fpUP4aRtEJPU"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Convert Text to Ints\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G7WYP3yOEJD_"
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train_df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "umryHRNyEZT1"
   },
   "source": [
    "---\n",
    "\n",
    "Converts Tokens to Sequences of tokens\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfXn6jU5EYnY"
   },
   "outputs": [],
   "source": [
    "X_train = tokenizer.texts_to_sequences(train_df['text'])\n",
    "X_test = tokenizer.texts_to_sequences(test_df['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FWF43h4JEe1c"
   },
   "source": [
    "---\n",
    "\n",
    "Determine Max Length of a Tweet\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wC_xRvDhEekB",
    "outputId": "55794cbe-c4bd-4727-cc22-b4cd18ec2b71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "maxlen = determine_maxlen(X_train, percentile=99)\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjiOGWO0Elsy"
   },
   "source": [
    "---\n",
    "\n",
    "Add padding to ensure all token sequences are the same shape.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rzvNooe6vBps"
   },
   "outputs": [],
   "source": [
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzfQ_thiEwUR"
   },
   "source": [
    "---\n",
    "\n",
    "Split Train and Dev Sets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G2rRd2-CvF31"
   },
   "outputs": [],
   "source": [
    "y_train = train_df['target'].values\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oWjtzjxOEzUy"
   },
   "source": [
    "---\n",
    "\n",
    "Run Hyperband Search on data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pVpKzq6LvICD",
    "outputId": "197dab5c-f14b-4ae8-ccb9-8f97d8fe4479"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 55 Complete [00h 01m 21s]\n",
      "val_accuracy: 0.7754431962966919\n",
      "\n",
      "Best val_accuracy So Far: 0.8049901723861694\n",
      "Total elapsed time: 00h 41m 19s\n",
      "Evaluating batch size 64\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7906 - loss: 0.5110\n",
      "Loss: 0.4946240484714508, MAPE: 0.8049901723861694\n",
      "Evaluating batch size 128\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7914 - loss: 0.5105\n",
      "Loss: 0.4946240186691284, MAPE: 0.8049901723861694\n",
      "Evaluating batch size 256\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7933 - loss: 0.5067\n",
      "Loss: 0.4946240484714508, MAPE: 0.8049901723861694\n",
      "Evaluating batch size 512\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7978 - loss: 0.5016\n",
      "Loss: 0.4946240186691284, MAPE: 0.8049901723861694\n",
      "Evaluating batch size 1024\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.8020 - loss: 0.5041\n",
      "Loss: 0.4946240186691284, MAPE: 0.8049901723861694\n",
      "Evaluating batch size 2048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.8050 - loss: 0.4946\n",
      "Loss: 0.4946240186691284, MAPE: 0.8049901723861694\n"
     ]
    }
   ],
   "source": [
    "\n",
    "out_folder = \"Transformer\"\n",
    "hyp_search_folder = \"hyperband_search\"\n",
    "batch_sizes = [64, 128, 256, 512, 1024, 2048]\n",
    "\n",
    "hyperband = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=15,\n",
    "    factor=4,\n",
    "    hyperband_iterations=5,\n",
    "    directory=out_folder,\n",
    "    project_name=hyp_search_folder,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "\n",
    "hyperband.search(X_train, y_train, epochs=5, validation_data=(X_dev, y_dev))\n",
    "\n",
    "\n",
    "best_model = hyperband.get_best_models(num_models=1)[0]\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(f\"Evaluating batch size {batch_size}\")\n",
    "    loss, mape = best_model.evaluate(X_dev, y_dev, batch_size=batch_size)\n",
    "    print(f\"Loss: {loss}, MAPE: {mape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KBmohVbE43j"
   },
   "source": [
    "---\n",
    "\n",
    "Print Summary of Search for param optimization\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YYV7bsY86NO5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "key_dim (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 40, 'max_value': 56, 'step': 4, 'sampling': 'linear'}\n",
      "dense_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 88, 'max_value': 128, 'step': 8, 'sampling': 'linear'}\n",
      "dropout_rate (Float)\n",
      "{'default': 0.5, 'conditions': [], 'min_value': 0.5, 'max_value': 0.6, 'step': 0.05, 'sampling': 'linear'}\n",
      "activation (Choice)\n",
      "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
      "Results summary\n",
      "Results in Transformer\\hyperband_search\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 0003 summary\n",
      "Hyperparameters:\n",
      "key_dim: 56\n",
      "dense_units: 88\n",
      "dropout_rate: 0.55\n",
      "activation: relu\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.8049901723861694\n",
      "\n",
      "Trial 0033 summary\n",
      "Hyperparameters:\n",
      "key_dim: 52\n",
      "dense_units: 120\n",
      "dropout_rate: 0.5\n",
      "activation: relu\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.8043335676193237\n",
      "\n",
      "Trial 0044 summary\n",
      "Hyperparameters:\n",
      "key_dim: 44\n",
      "dense_units: 120\n",
      "dropout_rate: 0.55\n",
      "activation: relu\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.8043335676193237\n",
      "\n",
      "Trial 0001 summary\n",
      "Hyperparameters:\n",
      "key_dim: 56\n",
      "dense_units: 104\n",
      "dropout_rate: 0.55\n",
      "activation: relu\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.803676962852478\n",
      "\n",
      "Trial 0008 summary\n",
      "Hyperparameters:\n",
      "key_dim: 40\n",
      "dense_units: 88\n",
      "dropout_rate: 0.55\n",
      "activation: tanh\n",
      "tuner/epochs: 15\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.803676962852478\n",
      "\n",
      "Trial 0046 summary\n",
      "Hyperparameters:\n",
      "key_dim: 48\n",
      "dense_units: 104\n",
      "dropout_rate: 0.55\n",
      "activation: tanh\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.8030203580856323\n",
      "\n",
      "Trial 0014 summary\n",
      "Hyperparameters:\n",
      "key_dim: 48\n",
      "dense_units: 120\n",
      "dropout_rate: 0.5\n",
      "activation: relu\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.8017071485519409\n",
      "\n",
      "Trial 0032 summary\n",
      "Hyperparameters:\n",
      "key_dim: 40\n",
      "dense_units: 96\n",
      "dropout_rate: 0.55\n",
      "activation: relu\n",
      "tuner/epochs: 15\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 0\n",
      "tuner/round: 0\n",
      "Score: 0.8017071485519409\n",
      "\n",
      "Trial 0048 summary\n",
      "Hyperparameters:\n",
      "key_dim: 44\n",
      "dense_units: 104\n",
      "dropout_rate: 0.55\n",
      "activation: tanh\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.8017071485519409\n",
      "\n",
      "Trial 0037 summary\n",
      "Hyperparameters:\n",
      "key_dim: 40\n",
      "dense_units: 120\n",
      "dropout_rate: 0.5\n",
      "activation: tanh\n",
      "tuner/epochs: 4\n",
      "tuner/initial_epoch: 0\n",
      "tuner/bracket: 1\n",
      "tuner/round: 0\n",
      "Score: 0.8010505437850952\n"
     ]
    }
   ],
   "source": [
    "hyperband.search_space_summary()\n",
    "\n",
    "hyperband.results_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ym3qAK-E_b9"
   },
   "source": [
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i6CkzWBKvKdX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,935,616</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">115,488</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">11,352</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">88</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,935,616\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m115,488\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │        \u001b[38;5;34m256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m88\u001b[0m)        │     \u001b[38;5;34m11,352\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m88\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m89\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,062,801</span> (7.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,062,801\u001b[0m (7.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,062,801</span> (7.87 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,062,801\u001b[0m (7.87 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.9133 - loss: 0.2549 - val_accuracy: 0.7873 - val_loss: 0.7445\n",
      "Epoch 2/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.9233 - loss: 0.2158 - val_accuracy: 0.7781 - val_loss: 0.8546\n",
      "Epoch 3/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.9291 - loss: 0.2031 - val_accuracy: 0.7859 - val_loss: 0.7664\n",
      "Epoch 4/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.9349 - loss: 0.1821 - val_accuracy: 0.7846 - val_loss: 0.7160\n",
      "Epoch 5/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.9405 - loss: 0.1689 - val_accuracy: 0.7781 - val_loss: 0.7569\n",
      "Epoch 6/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 972ms/step - accuracy: 0.9450 - loss: 0.1607 - val_accuracy: 0.7781 - val_loss: 0.8650\n",
      "Epoch 7/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.9500 - loss: 0.1494 - val_accuracy: 0.7735 - val_loss: 0.9769\n",
      "Epoch 8/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.9524 - loss: 0.1376 - val_accuracy: 0.7800 - val_loss: 0.9845\n",
      "Epoch 9/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.9543 - loss: 0.1353 - val_accuracy: 0.7781 - val_loss: 0.9478\n",
      "Epoch 10/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.9600 - loss: 0.1146 - val_accuracy: 0.7761 - val_loss: 0.9595\n",
      "Epoch 11/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.9618 - loss: 0.1063 - val_accuracy: 0.7754 - val_loss: 1.0301\n",
      "Epoch 12/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 969ms/step - accuracy: 0.9643 - loss: 0.0961 - val_accuracy: 0.7741 - val_loss: 1.1550\n",
      "Epoch 13/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 961ms/step - accuracy: 0.9669 - loss: 0.0914 - val_accuracy: 0.7741 - val_loss: 1.2165\n",
      "Epoch 14/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 973ms/step - accuracy: 0.9704 - loss: 0.0823 - val_accuracy: 0.7695 - val_loss: 1.2447\n",
      "Epoch 15/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 967ms/step - accuracy: 0.9743 - loss: 0.0757 - val_accuracy: 0.7741 - val_loss: 1.2580\n",
      "Epoch 16/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 980ms/step - accuracy: 0.9767 - loss: 0.0651 - val_accuracy: 0.7649 - val_loss: 1.3316\n",
      "Epoch 17/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 955ms/step - accuracy: 0.9764 - loss: 0.0679 - val_accuracy: 0.7689 - val_loss: 1.3634\n",
      "Epoch 18/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 957ms/step - accuracy: 0.9785 - loss: 0.0623 - val_accuracy: 0.7571 - val_loss: 1.4485\n",
      "Epoch 19/100\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 957ms/step - accuracy: 0.9795 - loss: 0.0571 - val_accuracy: 0.7617 - val_loss: 1.5107\n"
     ]
    }
   ],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
    "best_model.build(input_shape=(None, 28))\n",
    "best_model.summary()\n",
    "\n",
    "history = best_model.fit(X_train, y_train,epochs=100,batch_size=2048,validation_data=(X_dev, y_dev),callbacks= [stop_early])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IcnQkw76vMU4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = best_model.predict(X_test)\n",
    "predictions = (predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cegvmiYkvODn"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'id': test_df['id'], 'target': predictions.flatten()})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
